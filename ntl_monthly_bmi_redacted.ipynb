{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ts6rbxeBbp1h"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio\n",
        "!pip install rasterstats\n",
        "!pip install exactextract\n",
        "\n",
        "from monthly_ntl_clean_int_v3_base import downloadh5_dates, mask_to_zero, download_file, geturl, extract_offnadir_and_quality, apply_quality_mask, mosaic, zonalStats, interpolate_ntl_1d, apply_ephemeral_mask, resample_to_black_marble\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "import gzip\n",
        "from exactextract import exact_extract\n",
        "import io\n",
        "import tempfile\n",
        "import requests\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from pathlib import Path\n",
        "from bs4 import BeautifulSoup\n",
        "from getpass import getpass\n",
        "import urllib3\n",
        "import numpy as np\n",
        "from rasterio.enums import Resampling\n",
        "from rasterio.warp import reproject, calculate_default_transform\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6EvPbTRFb6Nk"
      },
      "outputs": [],
      "source": [
        "##set-up token and local directories\n",
        "token = ''\n",
        "#token from NASA Get it here: https://ladsweb.modaps.eosdis.nasa.gov/tools-and-services/data-download-scripts/#tokens\n",
        "\n",
        "loc_dir = Path(os.getcwd())\n",
        "\n",
        "#do not change these lines\n",
        "h5_folder = \"01 H5\" #name of location folder within local directory where h5 will be downloaded\n",
        "geotiff_folder = \"02 Geotiff\" #name of location folder within local directory where geotiff will be stored\n",
        "masked_folder = \"03 Masked\" #name of location folder within local directory where mosaic geotiff will be stored\n",
        "average_folder = \"04 Average\" #name of location folder within local directory where averaged mosaic geotiff will be stored\n",
        "mosaic_folder = \"05 Mosaic\" #name of location folder within local directory where mosaic geotiff will be stored\n",
        "csv_folder = \"06 CSV\" #name of location folder within local directory where csv will be stored\n",
        "shapefile_folder = \"Shapefile\" #name of location folder within local directory where shapefile is stored\n",
        "\n",
        "#add your shapefile here\n",
        "zones = \"ph.shp\"\n",
        "#this corresponds to your adm bound code\n",
        "zones_field = \"ADM1_PCODE\"\n",
        "#this corresponds to the tiles needed to be downloaded based on a specific area of interest\n",
        "h5tiles_csv = \"PH_TileList3.csv\"\n",
        "\n",
        "loc_dir = Path(os.getcwd())\n",
        "\n",
        "# Define paths\n",
        "h5_dir = loc_dir / h5_folder\n",
        "geotiff_dir = loc_dir / geotiff_folder\n",
        "masked_dir = loc_dir / masked_folder\n",
        "mosaic_dir = loc_dir / mosaic_folder\n",
        "shapefile_dir = loc_dir / shapefile_folder / zones\n",
        "csv_dir = loc_dir / csv_folder\n",
        "\n",
        "# Read the CSV of tiles\n",
        "tiles = pd.read_csv(loc_dir / h5tiles_csv)\n",
        "h5tiles_list = tiles['TileID'].tolist()\n",
        "\n",
        "# Define the year for which data will be downloaded and processed\n",
        "year = 2023  # Example: User input for the year\n",
        "\n",
        "# angles = [\"OffNadir_Composite_Snow_Free\", \"NearNadir_Composite_Snow_Free\", \"AllAngle_Composite_Snow_Free\"]\n",
        "angles = [\"AllAngle_Composite_Snow_Free\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6lYNNBMzMOG",
        "outputId": "3c4fb328-c410-4706-dd54-e541041c1055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#optional. for auto-upload to your google drive.\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "from shutil import move\n",
        "\n",
        "# --- MOUNT GOOGLE DRIVE ---\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eHF1h-aV72rG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97789ff2-8e90-4561-f233-c2b26888e74e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-4155216342.py:46: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
            "  geometry = [aoi.unary_union]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üåê Searching: https://eogdata.mines.edu/nighttime_light/annual/v22/2023/\n",
            "‚¨áÔ∏è Downloading and clipping: VNL_v22_npp_2023_global_vcmslcfg_c202402131000.lit_mask.dat.tif.gz\n",
            "‚úÖ Saved: 2023_lit_mask_clipped.tif\n"
          ]
        }
      ],
      "source": [
        "# Replace with your actual EOG credentials; Register at: https://eogauth-new.mines.edu/realms/eog/protocol/openid-connect/auth\n",
        "os.environ[\"EOG_USERNAME\"] = \"\"\n",
        "os.environ[\"EOG_PASSWORD\"] = \"\"\n",
        "\n",
        "def get_access_token(username, password):\n",
        "    try:\n",
        "        token_url = \"https://eogauth-new.mines.edu/realms/eog/protocol/openid-connect/token\"\n",
        "        params = {\n",
        "            \"client_id\": \"\",\n",
        "            \"client_secret\": \"\",\n",
        "            \"username\": username,\n",
        "            \"password\": password,\n",
        "            \"grant_type\": \"password\"\n",
        "        }\n",
        "        response = requests.post(token_url, data=params)\n",
        "        response.raise_for_status()\n",
        "        return response.json().get(\"access_token\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to get access token: {e}\")\n",
        "        return None\n",
        "\n",
        "def download_and_clip_lit_mask(year: int, output_dir: str, aoi_shapefile: str):\n",
        "    \"\"\"\n",
        "    Downloads and clips annual lit_mask.dat.tif.gz from NOAA for a selected year.\n",
        "    Saves the clipped GeoTIFF to output_dir.\n",
        "    \"\"\"\n",
        "\n",
        "    # Determine correct version\n",
        "    version = \"v21\" if year <= 2021 else \"v22\"\n",
        "    base_url = f\"https://eogdata.mines.edu/nighttime_light/annual/{version}\"\n",
        "    product_keyword = \"lit_mask.dat.tif.gz\"\n",
        "\n",
        "    # Auth\n",
        "    username = os.getenv(\"EOG_USERNAME\") or input(\"EOG Username: \")\n",
        "    password = os.getenv(\"EOG_PASSWORD\") or getpass(\"EOG Password: \")\n",
        "    token = get_access_token(username, password)\n",
        "    if not token:\n",
        "        return\n",
        "\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Read AOI\n",
        "    aoi = gpd.read_file(aoi_shapefile).to_crs(\"EPSG:4326\")\n",
        "    geometry = [aoi.unary_union]\n",
        "\n",
        "    # Construct folder URL\n",
        "    folder_url = f\"{base_url}/{year}/\"\n",
        "    print(f\"\\nüåê Searching: {folder_url}\")\n",
        "\n",
        "    session = requests.Session()\n",
        "    session.headers.update(headers)\n",
        "\n",
        "    try:\n",
        "        resp = session.get(folder_url, verify=False)\n",
        "        if resp.status_code != 200:\n",
        "            print(f\"‚ùå Cannot access {folder_url}\")\n",
        "            return\n",
        "\n",
        "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "        file_links = [a['href'] for a in soup.find_all('a', href=True) if product_keyword in a['href']]\n",
        "        if not file_links:\n",
        "            print(f\"‚ùå No lit_mask file found for {year}\")\n",
        "            return\n",
        "\n",
        "        filename = file_links[0]\n",
        "        clipped_outfile = output_path / f\"{year}_lit_mask_clipped.tif\"\n",
        "        if clipped_outfile.exists():\n",
        "            print(f\"‚è© Skipping existing: {clipped_outfile.name}\")\n",
        "            return\n",
        "\n",
        "        full_url = folder_url + filename\n",
        "        print(f\"‚¨áÔ∏è Downloading and clipping: {filename}\")\n",
        "\n",
        "        with session.get(full_url, stream=True, verify=False) as r:\n",
        "            r.raise_for_status()\n",
        "\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".tif\") as temp_tif:\n",
        "                with gzip.open(io.BytesIO(r.content)) as gz:\n",
        "                    shutil.copyfileobj(gz, temp_tif)\n",
        "\n",
        "        # Clip the temporary .tif to AOI\n",
        "        with rasterio.open(temp_tif.name) as src:\n",
        "            out_image, out_transform = mask(src, geometry, crop=True)\n",
        "            out_meta = src.meta.copy()\n",
        "            out_meta.update({\n",
        "                \"driver\": \"GTiff\",\n",
        "                \"height\": out_image.shape[1],\n",
        "                \"width\": out_image.shape[2],\n",
        "                \"transform\": out_transform\n",
        "            })\n",
        "\n",
        "            with rasterio.open(clipped_outfile, \"w\", **out_meta) as dest:\n",
        "                dest.write(out_image)\n",
        "\n",
        "        os.remove(temp_tif.name)\n",
        "        print(f\"‚úÖ Saved: {clipped_outfile.name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error for year {year}: {e}\")\n",
        "\n",
        "# function to resampling mask to match ref raster\n",
        "\n",
        "def resample_mask_to_match(mask_path, reference_path, output_path):\n",
        "    \"\"\"Resample mask raster to match the dimensions and projection of a reference raster.\"\"\"\n",
        "\n",
        "    # Check if required files exist\n",
        "    if not os.path.exists(mask_path):\n",
        "        raise FileNotFoundError(f\"‚ö†Ô∏è Mask file not found: {mask_path}\")\n",
        "    if not os.path.exists(reference_path):\n",
        "        raise FileNotFoundError(f\"‚ö†Ô∏è Reference file not found: {reference_path}\")\n",
        "\n",
        "    with rasterio.open(reference_path) as ref:\n",
        "        ref_meta = ref.meta.copy()\n",
        "        ref_transform = ref.transform\n",
        "        ref_crs = ref.crs\n",
        "        ref_height = ref.height\n",
        "        ref_width = ref.width\n",
        "\n",
        "        with rasterio.open(mask_path) as mask:\n",
        "            mask_data = mask.read(1)  # Read single-band data\n",
        "            mask_transform = mask.transform\n",
        "            mask_crs = mask.crs\n",
        "\n",
        "            # Prepare resampled array\n",
        "            mask_resampled = np.empty((ref_height, ref_width), dtype=mask_data.dtype)\n",
        "\n",
        "            # Perform the resampling\n",
        "            reproject(\n",
        "                source=mask_data,\n",
        "                destination=mask_resampled,\n",
        "                src_transform=mask_transform,\n",
        "                src_crs=mask_crs,\n",
        "                dst_transform=ref_transform,\n",
        "                dst_crs=ref_crs,\n",
        "                resampling=Resampling.nearest\n",
        "            )\n",
        "\n",
        "            # Update metadata\n",
        "            ref_meta.update({\n",
        "                \"height\": ref_height,\n",
        "                \"width\": ref_width,\n",
        "                \"transform\": ref_transform,\n",
        "                \"count\": 1,  # Single band\n",
        "                \"dtype\": mask_data.dtype\n",
        "            })\n",
        "\n",
        "            # Save resampled mask\n",
        "            with rasterio.open(output_path, \"w\", **ref_meta) as dest:\n",
        "                dest.write(mask_resampled, 1)  # Write to the first band\n",
        "\n",
        "    print(f\"‚úÖ Resampling complete. Output saved at: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "download_and_clip_lit_mask(\n",
        "    year=year,\n",
        "    output_dir=\"ntl_clipped_outputs\",\n",
        "    aoi_shapefile=shapefile_dir\n",
        ")\n",
        "\n",
        "ephemeral_mask_path = f\"ntl_clipped_outputs/{year}_lit_mask_clipped.tif\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q6NgKIPCU-dP",
        "outputId": "75b1be7d-3260-47f6-b058-2f67b3136616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023091.h29v08.001.2023128224032.h5_Filtered_EphemeralMasked_Interpolated\n",
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023305.h29v08.001.2024005193108.h5_Filtered_EphemeralMasked_Interpolated\n",
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023152.h29v08.001.2023199005155.h5_Filtered_EphemeralMasked_Interpolated\n",
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023213.h29v08.001.2023290162442.h5_Filtered_EphemeralMasked_Interpolated\n",
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023060.h29v08.001.2023098211823.h5_Filtered_EphemeralMasked_Interpolated\n",
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023001.h29v08.001.2023039142538.h5_Filtered_EphemeralMasked_Interpolated\n",
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023182.h29v08.001.2023240145712.h5_Filtered_EphemeralMasked_Interpolated\n",
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023335.h29v08.001.2024016035159.h5_Filtered_EphemeralMasked_Interpolated\n",
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023244.h29v08.001.2023290163458.h5_Filtered_EphemeralMasked_Interpolated\n",
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023121.h29v08.001.2023159150121.h5_Filtered_EphemeralMasked_Interpolated\n",
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023032.h29v08.001.2023067145010.h5_Filtered_EphemeralMasked_Interpolated\n",
            "üîç Scanning file: AllAngle_Composite_Snow_Free_VNP46A3.A2023274.h29v08.001.2023333141821.h5_Filtered_EphemeralMasked_Interpolated\n",
            "Processing A2023091 for AllAngle_Composite_Snow_Free: 1 files\n",
            "Processing A2023091 for AllAngle_Composite_Snow_Free: 1 files\n",
            "Mosaicking 1 files into /content/05 Mosaic/A2023091/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023091.tif\n",
            "Finished in 0.1020 seconds.\n",
            "Performing Zonal Statistics: /content/06 CSV/A2023091/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023091_2023_v3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
            "/usr/local/lib/python3.11/dist-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/ops.py:259: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
            "  shell = type(geom.exterior)(zip(*func(*zip(*geom.exterior.coords))))\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/measurement.py:50: RuntimeWarning: invalid value encountered in area\n",
            "  return lib.area(geometry, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/ops.py:261: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
            "  type(ring)(zip(*func(*zip(*ring.coords))))\n",
            "/usr/local/lib/python3.11/dist-packages/osgeo/gdal.py:312: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zonal statistics saved to /content/06 CSV/A2023091/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023091_2023_v3.csv\n",
            "Finished in 84.1213 seconds.\n",
            "Performing Zonal Statistics: /content/06 CSV/A2023091/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023091_2023_v3.csv\n",
            "Finished in 0.0000 seconds.\n",
            "Processing A2023305 for AllAngle_Composite_Snow_Free: 1 files\n",
            "Processing A2023305 for AllAngle_Composite_Snow_Free: 1 files\n",
            "Mosaicking 1 files into /content/05 Mosaic/A2023305/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023305.tif\n",
            "Finished in 0.0581 seconds.\n",
            "Performing Zonal Statistics: /content/06 CSV/A2023305/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023305_2023_v3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
            "/usr/local/lib/python3.11/dist-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/ops.py:259: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
            "  shell = type(geom.exterior)(zip(*func(*zip(*geom.exterior.coords))))\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/measurement.py:50: RuntimeWarning: invalid value encountered in area\n",
            "  return lib.area(geometry, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/ops.py:261: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
            "  type(ring)(zip(*func(*zip(*ring.coords))))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zonal statistics saved to /content/06 CSV/A2023305/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023305_2023_v3.csv\n",
            "Finished in 86.2911 seconds.\n",
            "Performing Zonal Statistics: /content/06 CSV/A2023305/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023305_2023_v3.csv\n",
            "Finished in 0.0000 seconds.\n",
            "Processing A2023152 for AllAngle_Composite_Snow_Free: 1 files\n",
            "Processing A2023152 for AllAngle_Composite_Snow_Free: 1 files\n",
            "Mosaicking 1 files into /content/05 Mosaic/A2023152/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023152.tif\n",
            "Finished in 0.0547 seconds.\n",
            "Performing Zonal Statistics: /content/06 CSV/A2023152/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023152_2023_v3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
            "/usr/local/lib/python3.11/dist-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/ops.py:259: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
            "  shell = type(geom.exterior)(zip(*func(*zip(*geom.exterior.coords))))\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/measurement.py:50: RuntimeWarning: invalid value encountered in area\n",
            "  return lib.area(geometry, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/ops.py:261: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
            "  type(ring)(zip(*func(*zip(*ring.coords))))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zonal statistics saved to /content/06 CSV/A2023152/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023152_2023_v3.csv\n",
            "Finished in 85.2430 seconds.\n",
            "Performing Zonal Statistics: /content/06 CSV/A2023152/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023152_2023_v3.csv\n",
            "Finished in 0.0000 seconds.\n",
            "Processing A2023213 for AllAngle_Composite_Snow_Free: 1 files\n",
            "Processing A2023213 for AllAngle_Composite_Snow_Free: 1 files\n",
            "Mosaicking 1 files into /content/05 Mosaic/A2023213/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023213.tif\n",
            "Finished in 0.0525 seconds.\n",
            "Performing Zonal Statistics: /content/06 CSV/A2023213/AllAngle_Composite_Snow_Free/Mosaic_AllAngle_Composite_Snow_Free_A2023213_2023_v3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
            "/usr/local/lib/python3.11/dist-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/ops.py:259: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
            "  shell = type(geom.exterior)(zip(*func(*zip(*geom.exterior.coords))))\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/measurement.py:50: RuntimeWarning: invalid value encountered in area\n",
            "  return lib.area(geometry, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/shapely/ops.py:261: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
            "  type(ring)(zip(*func(*zip(*ring.coords))))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-250469933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Performing Zonal Statistics: {output_csv}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mzonalStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmosaic_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapefile_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzones_field\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished in %.4f seconds.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/monthly_ntl_clean_int_v3_base.py\u001b[0m in \u001b[0;36mzonalStats\u001b[0;34m(raster_src, zones, csv, field_id)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;31m# Compute zonal statistics using exact_extract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexact_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraster_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stdev\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"median\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;31m# Extract statistics from 'properties' key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/exactextract/exact_extract.py\u001b[0m in \u001b[0;36mexact_extract\u001b[0;34m(rast, vec, ops, weights, include_cols, include_geom, strategy, max_cells_in_memory, grid_compat_tol, output, output_options, progress)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"progress should be True or a function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "### main processor\n",
        "\n",
        "# Step 1: Download H5 files for the specified year\n",
        "try:\n",
        "    downloadh5_dates(year, loc_dir, h5_folder, token, h5tiles_list)\n",
        "except Exception as e:\n",
        "    print(f\"Unable to download. Error: {e}\")\n",
        "\n",
        "# Step 2: Convert H5 files to GeoTIFF and filter quality\n",
        "paths = h5_dir.glob('**/*.h5')  # Locate all H5 files in the specified directory\n",
        "\n",
        "for path in paths:\n",
        "    a = path.name.split('.')\n",
        "    # dest = Path(str(path.parents[1]).replace(h5_folder, geotiff_folder)) / a[2]\n",
        "    for angle in angles:\n",
        "        dest = Path(str(path.parents[1]).replace(h5_folder, geotiff_folder)) / a[2] / angle\n",
        "\n",
        "        if not os.path.exists(dest):\n",
        "            os.makedirs(dest)\n",
        "\n",
        "        print(f'Extracting {angle} and Quality layers for:', path)\n",
        "        start = time.perf_counter()\n",
        "        composite_output, quality_output = extract_offnadir_and_quality(path, dest, angle)\n",
        "        print(\"Extraction finished in %.4f seconds.\" % (time.perf_counter() - start))\n",
        "\n",
        "        if composite_output and quality_output:\n",
        "            start = time.perf_counter()\n",
        "            quality_filtered_output = apply_quality_mask(Path(composite_output), Path(quality_output), Path(dest))\n",
        "            # filtered_output = apply_quality_mask(Path(composite_output), Path(quality_output), Path(dest))\n",
        "            print(\"Filtering finished in %.4f seconds.\" % (time.perf_counter() - start))\n",
        "\n",
        "            # ‚úÖ Ensure `quality_filtered_output` exists before calling resampling\n",
        "            if not os.path.exists(quality_filtered_output):\n",
        "                raise RuntimeError(\"‚ùå Failed to generate quality_filtered_output. Stopping execution.\")\n",
        "\n",
        "            # # Step 3: Resampling\n",
        "            resampled_mask_path = dest / \"resampled_mask.tif\"\n",
        "            print(\"üìå Running Resampling Step...\")\n",
        "            resample_mask_to_match(ephemeral_mask_path, quality_filtered_output, resampled_mask_path)\n",
        "\n",
        "            # Step 4: Apply ephemeral mask\n",
        "            ephemeral_output_path = dest / f\"{Path(quality_filtered_output).stem}_EphemeralMasked.tif\"\n",
        "            print(\"üìå Applying Ephemeral Mask...\")\n",
        "            ephemeral_filtered_output = apply_ephemeral_mask(quality_filtered_output, resampled_mask_path, ephemeral_output_path)\n",
        "\n",
        "            # Step 5: Resample to Black Marble\n",
        "            resampled_output_path = dest / f\"{Path(ephemeral_filtered_output).stem}_Resampled.tif\"\n",
        "            print(\"üìå Resampling to Black Marble...\")\n",
        "            final_output = resample_to_black_marble(ephemeral_filtered_output, quality_filtered_output, resampled_output_path)\n",
        "\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Extraction failed for {path}, skipping filtering!\")\n",
        "            print(f\"  - Composite Output: {composite_output}\")\n",
        "            print(f\"  - Quality Output: {quality_output}\")\n",
        "\n",
        "paths = geotiff_dir.glob('**/*/*/*Resampled*.tif')\n",
        "\n",
        "# Step 6: Apply linear imputation\n",
        "# Organize by (tile_id, angle)\n",
        "paths_by_id = defaultdict(lambda: defaultdict(list))\n",
        "for path in paths:\n",
        "    tile_id = path.parent.parent.name\n",
        "    angle = path.parent.name\n",
        "    parts = path.stem.split('.')\n",
        "    if len(parts) > 4:\n",
        "        unique_id = parts[1]  # e.g., A2021035\n",
        "        paths_by_id[(tile_id, angle)][unique_id] = path\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# Iterate per (tile_id, angle)\n",
        "for (tile_id, angle), tif_dict in paths_by_id.items():\n",
        "    # Map from datetime ‚Üí path\n",
        "    date_map = {}\n",
        "    for k, p in tif_dict.items():\n",
        "        try:\n",
        "            dt = datetime.strptime(k[1:], \"%Y%j\")  # strip 'A'\n",
        "            # dt = datetime.datetime.strptime(k[1:], \"%Y%j\")\n",
        "            date_map[dt] = p\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to parse date from {k}: {e}\")\n",
        "\n",
        "    years = sorted(set(d.year for d in date_map))\n",
        "    for year in years:\n",
        "        if year == min(years):\n",
        "            continue  # skip first year ‚Äî no Dec from previous year\n",
        "\n",
        "        # Build rolling window: Dec of prev year + Jan‚ÄìDec of current year\n",
        "        window_months = [datetime(year - 1, 12, 1)] + [datetime(year, m, 1) for m in range(1, 13)]\n",
        "        tif_paths = [date_map.get(dt) for dt in window_months if dt in date_map]\n",
        "\n",
        "        if len(tif_paths) < 13:\n",
        "            print(f\"‚ö†Ô∏è Skipping {tile_id}-{angle} {year}: incomplete 13-month window.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"‚è≥ Interpolating pixel time series for {tile_id} - {angle} ({year})\")\n",
        "        output_dir = tif_paths[0].parent  # output stays in angle folder\n",
        "        start = time.perf_counter()\n",
        "\n",
        "        interpolated_paths = interpolate_ntl_1d(\n",
        "            tif_paths=tif_paths,\n",
        "            output_dir=output_dir,\n",
        "            target_year=year,\n",
        "            masked_value=6553.5\n",
        "        )\n",
        "\n",
        "        target_dates = [d for d in [datetime.strptime(p.stem.split('.')[1][1:], \"%Y%j\") for p in tif_paths]\n",
        "                        if d.year == year]\n",
        "\n",
        "        # Sanity check\n",
        "        if len(target_dates) != len(interpolated_paths):\n",
        "            print(f\"‚ö†Ô∏è Mismatch: {len(target_dates)} dates vs {len(interpolated_paths)} interpolated files\")\n",
        "\n",
        "        # Rename properly\n",
        "        for date, interp_path in zip(target_dates, interpolated_paths):\n",
        "            date_str = f\"A{date.year}{date.timetuple().tm_yday:03d}\"\n",
        "            orig_match = [p for p in tif_paths if date_str in p.name]\n",
        "\n",
        "            if orig_match:\n",
        "                expected_name = orig_match[0].name.replace('Resampled', 'Interpolated')\n",
        "                renamed_path = interp_path.parent / expected_name\n",
        "                interp_path.rename(renamed_path)\n",
        "                print(f\"üìù Renamed {interp_path.name} ‚Üí {renamed_path.name}\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è No match for {date_str}\")\n",
        "\n",
        "\n",
        "# Step 7: Apply Zonal Statistics\n",
        "paths_by_id = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "for tif in geotiff_dir.glob('**/*/*/*Interpolated*.tif'):\n",
        "\n",
        "    filename = tif.stem  # no .tif\n",
        "    parts = filename.split('_')\n",
        "\n",
        "    print(f\"üîç Scanning file: {filename}\")  # Add this\n",
        "\n",
        "    if len(parts) >= 5 and 'VNP46A3' in parts[4]:\n",
        "        main_block = parts[4]  # e.g., 'VNP46A3.A2022274.h29v06...'\n",
        "        try:\n",
        "            unique_id = main_block.split('.')[1]  # extracts 'A2022274'\n",
        "            angle = Path(tif).parent.name  # keep this as is\n",
        "            if angle in angles:\n",
        "                paths_by_id[unique_id][angle].append(tif)\n",
        "        except IndexError:\n",
        "            print(f\"‚ö†Ô∏è Could not extract unique_id from {filename}\")\n",
        "\n",
        "for unique_id, angles_dict in paths_by_id.items():\n",
        "    for angle, tif_list in angles_dict.items():\n",
        "        print(f\"Processing {unique_id} for {angle}: {len(tif_list)} files\")\n",
        "\n",
        "        mosaic_output = mosaic_dir / unique_id / angle / f\"Mosaic_{angle}_{unique_id}.tif\"\n",
        "\n",
        "        output_csv = csv_dir / unique_id / angle / f\"{mosaic_output.stem}_{year}_v3.csv\"\n",
        "\n",
        "        if output_csv.exists():\n",
        "            print(f\"Skipping {unique_id} - {angle}, CSV already exists: {output_csv}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing {unique_id} for {angle}: {len(tif_list)} files\")\n",
        "\n",
        "        os.makedirs(mosaic_output.parent, exist_ok=True)\n",
        "\n",
        "        if tif_list:\n",
        "            print(f\"Mosaicking {len(tif_list)} files into {mosaic_output}\")\n",
        "            start = time.perf_counter()\n",
        "            mosaic(tif_list, str(mosaic_output))\n",
        "            print(\"Finished in %.4f seconds.\" % (time.perf_counter() - start))\n",
        "\n",
        "            os.makedirs(csv_dir, exist_ok=True)\n",
        "            output_csv = csv_dir / unique_id / angle / f\"{mosaic_output.stem}_{year}_v3.csv\"\n",
        "            os.makedirs(output_csv.parent, exist_ok=True)\n",
        "\n",
        "\n",
        "            if output_csv.exists():\n",
        "                print(f\"Skipping Zonal Statistics: {output_csv} already exists.\")\n",
        "            else:\n",
        "                print(f'Performing Zonal Statistics: {output_csv}')\n",
        "                start = time.perf_counter()\n",
        "                zonalStats(mosaic_output, shapefile_dir, output_csv, zones_field)\n",
        "                print(\"Finished in %.4f seconds.\" % (time.perf_counter() - start))\n",
        "\n",
        "            print(f'Performing Zonal Statistics: {output_csv}')\n",
        "            start = time.perf_counter()\n",
        "            print(\"Finished in %.4f seconds.\" % (time.perf_counter() - start))\n",
        "        else:\n",
        "            print(f\"No files found for {unique_id} - {angle}, skipping.\")\n",
        "\n",
        "# uncomment if needed\n",
        "# # --- CONFIGURATION ---\n",
        "# GDRIVE_FOLDER_ID = \"id_regency_bmi_2017\"  # Change to your actual Google Drive folder ID\n",
        "\n",
        "# GDRIVE_UPLOAD_FOLDER = f\"/content/drive/MyDrive/{GDRIVE_FOLDER_ID}\"\n",
        "\n",
        "# # Ensure the upload folder exists in Google Drive\n",
        "# if not os.path.exists(GDRIVE_UPLOAD_FOLDER):\n",
        "#     os.makedirs(GDRIVE_UPLOAD_FOLDER)\n",
        "\n",
        "# # Define the specific folder you want to upload\n",
        "# TARGET_FOLDER = \"06 CSV\"  # Change this if necessary\n",
        "\n",
        "# # Check if the target folder exists in Colab\n",
        "# folder_path = os.path.join(\"/content\", TARGET_FOLDER)\n",
        "# if not os.path.exists(folder_path):\n",
        "#     print(f\"‚ùå Folder '{TARGET_FOLDER}' not found in Colab environment.\")\n",
        "# else:\n",
        "#     zip_filename = f\"{TARGET_FOLDER}.zip\"\n",
        "\n",
        "#     # Compress the target folder into a ZIP file\n",
        "#     with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "#         for root, dirs, files in os.walk(folder_path):\n",
        "#             for file in files:\n",
        "#                 if file.endswith((\".gsheet\", \".gdoc\", \".gslides\")):\n",
        "#                     print(f\"Skipping Google file: {file}\")\n",
        "#                     continue\n",
        "\n",
        "#                 file_path = os.path.join(root, file)\n",
        "#                 arcname = os.path.relpath(file_path, folder_path)\n",
        "#                 zipf.write(file_path, arcname)\n",
        "\n",
        "#     print(f\"üì¶ Folder '{TARGET_FOLDER}' compressed as '{zip_filename}'.\")\n",
        "\n",
        "#     # Move ZIP file to Google Drive folder\n",
        "#     drive_path = os.path.join(GDRIVE_UPLOAD_FOLDER, zip_filename)\n",
        "#     move(zip_filename, drive_path)\n",
        "#     print(f\"‚úÖ Uploaded '{zip_filename}' to Google Drive at: {GDRIVE_UPLOAD_FOLDER}\")\n",
        "\n",
        "# print(\"üéâ Upload completed! Check your Google Drive folder.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjKYRSU4Juu7"
      },
      "outputs": [],
      "source": [
        "# shutil.rmtree(h5_dir)\n",
        "# shutil.rmtree(geotiff_dir)\n",
        "# # shutil.rmtree(masked_dir)\n",
        "# # shutil.rmtree(average_dir)\n",
        "shutil.rmtree(mosaic_dir)\n",
        "shutil.rmtree(csv_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_dVu_qSXC1D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}